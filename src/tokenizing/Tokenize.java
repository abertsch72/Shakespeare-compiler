package tokenizing;

public class Tokenize {

	// tokenize one char then request more chars until non-alphabetic -- then check last thing for keywords
}


/*
 * Tokens:
 * 	ID
 * 	END
 * 	kwACT_OR_SCENE
 * 	ROMAN_NUM
 * 	COLON
 * 	LBRACKET
 * 	kwENTER
 * 	kwEXIT
 * 	kwEXUENT
 * 	CHAR
 * 	COMMA
 * 	kwBYTE_OUTPUT
 * 	kwCHAR_OUTPUT
 * 	kwGOTO
 * 	kwBYTE_INPUT
 * 	kwCHAR_INPUT
 * 	kwPUSH
 * 	kwPOP
 * 	kwME
 * 	kwYOU
 * 	POS_ADJ
 * 	NEG_ADJ
 * 	kwPOS
 * 	kwNEG
 * 	kwZERO
 * 	kwIF_TRUE
 * 	kwIF_FALSE
 * 	RBRACKET
 */